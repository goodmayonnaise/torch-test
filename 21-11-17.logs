* 모델 레이어 정리

nn.Flatten(input_image)
: 레이어 초기화 + 픽셀값을 갖는 연속된 배열로 전환
레이어를 초기화해서 28x28의 2D 이미지를 784 픽셀 값을 갖는 연속된 배열로 변환


nn.Linear(in_features, out_features)
: 저장된 가중치와 bias를 사용하여 입력에 linear transformation을 적용하는 모듈

nn.Relu()(hidden_layer)
: 비선형 활성화 함수 Relu
비선형 활성화 함수는 모델의 입력과 출력 사이에 복잡한 mapping을 만들어줌
선형 변환 후에 적용되어 비선형을 도입하고, 신경망이 다양한 현상을 학습할 수 있도록 도와줌.
(다른 활성화 함수도 많음)

nn.Sequential(layer1, layer2, ...)
: 순서를 갖는 모듈의 컨테이너
데이터는 정의된 것과 같은 순서로 모든 모듈을 통해 전달됨
sequential 컨테이너를 사용하여 신경망을 빠르게 만들 수 있음

nn.Softmax(dim)
신경망의 마지막 선형 계층
각 클래스에 대한 예측 확률을 나타내도록 [0,1]범위로 비례하여 scale 됨
dim 매개변수는 값의 합이 1이 된다는 차원을 나타냄


* 모델 매개변수 정리
신경망 내부의 많은 계층들은 매개변수화된다.
즉, 학습 중에 최적화되는 가중치와 편향과 연관지어진다.
nn.Module을 상속하면 모델 객체 내부의 모든 필드들이 자동으로 추적되고
모델의 parameters() 및 named_parameters() 메소드로 모든 매개변수에 접근할 수 있게 된다.
