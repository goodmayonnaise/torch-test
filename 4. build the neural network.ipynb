{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신경망 모델 구성하기\n",
    "\n",
    "신경망은 데이터에 대한 연산을 수행하는 layer, module로 구성되어 있다.\n",
    "\n",
    "torch.nn name space는 신경망을 구성하는데 필요한 모든 구성 요소를 제공한다.\n",
    "\n",
    "pytorch의 모든 모듈은 서브 클래스 nn.Module의 subclass이다.\n",
    "\n",
    "신경망은 다른 layer로 구성된 모듈이다.\n",
    "\n",
    "이러한 중첩된 구조는 복잡한 아키텍처를 쉽게 구축하고 관리할 수 있다.\n",
    "\n",
    "FashionMNIST 데이터셋의 이미지들을 분류하는 신경망을 구성해보자\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# gpu 사용 확인\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define class\n",
    "신경망 모델을 nn.Module의 하위 클래스로 정의\n",
    "\n",
    "__init__에서 신경망 계층 초기화\n",
    "\n",
    "nn.Module을 상속받은 모든 클래스는 forward 메소드에 입력 데이터에 대한 연산들을 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module): # nn.Module의 하위 클래스로 정의\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# NeuralNetwork의 인스턴스를 생성하고 structure 출력\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 사용하기 위해 입력 데이터를 전달\n",
    "\n",
    "이는 일부 백그라운드 연산들과 함께 모델의 forward를 실행한다.\n",
    "--> model.forward()를 직접 호출하지 마라 \n",
    "\n",
    "모델에 입력을 호출하면 각 class에 대한 raw 예측값이 있는 10차원 텐서가 반환된다.\n",
    "\n",
    "raw 예측값을 nn.softmax 모듈의 인스턴스에 통과시켜 예측 확률을 얻는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class\n",
      "tensor([9], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(x)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(\"Predicted Class\")\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 레이어\n",
    "\n",
    "FashionMNIST 모델의 레이어를 분해해보자.\n",
    "\n",
    "이를 설명하기 위해 크기가 28x28인 이미지 3개의 샘플 미니배치를 가져와 네트워크를 통해 전달할 때 어떻게 되는지 확인하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3, 28, 28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Flatten\n",
    "\n",
    "nn.Flatten 레이어를 초기화해서 28x28의 2D 이미지를 784 픽셀 값을 갖는 연속된 배열로 변환하자.\n",
    "(dim=0의 미니배치 차원은 유지된다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Linear\n",
    "\n",
    "linear 레이어는 저장된 weights와 bias를 사용하여 입력에 linear transformation을 적용하는 모듈이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.ReLU\n",
    "\n",
    "비선형 activation 함수는 모델의 입력과 출력 사이에 복잡한 mapping을 만든다.\n",
    "\n",
    "비선형 활성화는 선형 변환 후에 적용되어 비선형성을 도입하고,\n",
    "\n",
    "신경망이 다양한 현상을 학습할 수 있도록 돕는다.\n",
    "\n",
    "이 모델에서는 nn.ReLU를 선형 계층들 사이에 사용하지만, 모델을 만들 때는 비선형성을 가진 다른 활성화를 도입할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU\n",
      "tensor([[0.0000, 0.4028, 0.0000, 0.5694, 0.0000, 0.0000, 0.3374, 0.3942, 0.5255,\n",
      "         0.1611, 0.1811, 0.0444, 0.4902, 0.6375, 0.1585, 0.0000, 0.1575, 0.0000,\n",
      "         0.0000, 0.1211],\n",
      "        [0.0000, 0.2777, 0.0000, 0.3033, 0.0000, 0.1457, 0.4572, 0.6595, 0.7586,\n",
      "         0.3265, 0.0000, 0.0000, 0.6714, 0.6085, 0.2807, 0.0544, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2468, 0.3046, 0.0000, 0.2696, 0.0000, 0.3854, 0.1379, 0.2452, 0.1252,\n",
      "         0.1132, 0.0434, 0.0000, 0.4872, 0.1672, 0.3276, 0.0000, 0.2342, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n",
      "After ReLU\n",
      "tensor([[0.0000, 0.4028, 0.0000, 0.5694, 0.0000, 0.0000, 0.3374, 0.3942, 0.5255,\n",
      "         0.1611, 0.1811, 0.0444, 0.4902, 0.6375, 0.1585, 0.0000, 0.1575, 0.0000,\n",
      "         0.0000, 0.1211],\n",
      "        [0.0000, 0.2777, 0.0000, 0.3033, 0.0000, 0.1457, 0.4572, 0.6595, 0.7586,\n",
      "         0.3265, 0.0000, 0.0000, 0.6714, 0.6085, 0.2807, 0.0544, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2468, 0.3046, 0.0000, 0.2696, 0.0000, 0.3854, 0.1379, 0.2452, 0.1252,\n",
      "         0.1132, 0.0434, 0.0000, 0.4872, 0.1672, 0.3276, 0.0000, 0.2342, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before ReLU\")\n",
    "print(hidden1)\n",
    "\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "\n",
    "print(\"After ReLU\")\n",
    "print(hidden1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Sequential\n",
    "\n",
    "nn.Sequential 순서를 갖는 모듈의 컨테이너이다.\n",
    "\n",
    "데이터는 정의된 것과 같은 순서로 모든 모듈을 통해 전달된다.\n",
    "\n",
    "순차 컨테이너를 사용하여 아래의 seq_modules과 같은 신경망을 빠르게 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0906,  0.3778, -0.0954, -0.2084,  0.1566, -0.1968, -0.0596, -0.1879,\n",
       "         -0.1914,  0.0277],\n",
       "        [-0.0925,  0.2887,  0.1030, -0.1780,  0.1468, -0.2322, -0.1520, -0.2773,\n",
       "         -0.1834,  0.0849],\n",
       "        [ 0.0867,  0.2833,  0.0787, -0.2091, -0.0080, -0.1986, -0.1048, -0.0694,\n",
       "         -0.0576, -0.0616]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten, # nn.Flatten 3, 28, 28 -> 3, 28*28\n",
    "    layer1, # nn.Linear 3, 28*28 ->\n",
    "    nn.ReLU(), \n",
    "    nn.Linear(20,10)\n",
    ")\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "logits = seq_modules(input_image)\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Softmax\n",
    "\n",
    "신경망의 마지막 선형 계층은 nn.Softmax 모듈에 전달될 logits를 반환한다.\n",
    "\n",
    "logits는 모델의 각 class에 대한 예측 확률을 나타내도록 [0,1]범위로 비례하여 scale된다.\n",
    "\n",
    "dim 매개변수는 값의 합이 1이 된다는 차원을 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1107, 0.1475, 0.0919, 0.0821, 0.1183, 0.0830, 0.0953, 0.0838, 0.0835,\n",
       "         0.1040],\n",
       "        [0.0942, 0.1379, 0.1145, 0.0865, 0.1196, 0.0819, 0.0887, 0.0783, 0.0860,\n",
       "         0.1125],\n",
       "        [0.1108, 0.1349, 0.1099, 0.0824, 0.1008, 0.0833, 0.0915, 0.0948, 0.0959,\n",
       "         0.0955]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)\n",
    "pred_probab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 매개변수\n",
    "\n",
    "신경망 내부의 많은 레이어들은 매개변수화된다.\n",
    "\n",
    "즉, 학습 중에 최적화되는 가중치와 편향과 연관지어진다.\n",
    "\n",
    "nn.Module을 상속하면 모델 객체 내부의 필드들이 자동으로 track되며,\n",
    "\n",
    "모델의 parameters() 및 named_parameters() 메소드로 모든 매개변수에 접근할 수 있게 된다.\n",
    "\n",
    "이 예제에서는 각 매개변수들을 순회하며, 매개변수의 크기와 값을 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n",
      "Layer : linear_relu_stack.0.weight | size torch.Size([512, 784]) | values : tensor([[ 0.0261, -0.0253, -0.0081,  ..., -0.0139,  0.0025,  0.0233],\n",
      "        [ 0.0144,  0.0136, -0.0313,  ...,  0.0174, -0.0203,  0.0298]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer : linear_relu_stack.0.bias | size torch.Size([512]) | values : tensor([0.0173, 0.0126], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer : linear_relu_stack.2.weight | size torch.Size([512, 512]) | values : tensor([[-0.0230, -0.0294, -0.0041,  ...,  0.0326, -0.0242, -0.0296],\n",
      "        [ 0.0266, -0.0211, -0.0200,  ...,  0.0442,  0.0242, -0.0016]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer : linear_relu_stack.2.bias | size torch.Size([512]) | values : tensor([ 0.0405, -0.0441], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer : linear_relu_stack.4.weight | size torch.Size([10, 512]) | values : tensor([[-0.0135, -0.0083, -0.0110,  ...,  0.0261, -0.0127,  0.0112],\n",
      "        [-0.0131,  0.0436, -0.0272,  ...,  0.0372, -0.0026,  0.0269]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer : linear_relu_stack.4.bias | size torch.Size([10]) | values : tensor([-0.0034,  0.0333], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model structure\")\n",
    "print(model)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    # print(param)\n",
    "    # print(param[:2])\n",
    "    print(f\"Layer : {name} | size {param.size()} | values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd7d8ae84c30c9b148779bedbfd4b6b894c49078e9fff681c5971088fae95644"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('torch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
