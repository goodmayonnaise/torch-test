{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 매개변수 최적화\n",
    "이제 모델과 데이터가 준비됐으니, 데이터에 매개변수를 최적화하여 모델을 학습하고, 검증하고, 테스트 할 차례\n",
    "\n",
    "모델을 학습하는 과정은 반복적인 과정을 거친다.\n",
    "\n",
    "각 에폭에서 모델은 출력을 추측하고, 추측과 정답 사이의 loss를 계산하고, 매개변수에 대한 오류의 derivative를 수집한 뒤, 경사하강법을 사용하여 이 파라미터들을 optimize(최적화)한다.\n",
    "\n",
    "이 과정에 대한 자세한 설명은 아래의 링크를 참고\n",
    "\n",
    "https://www.youtube.com/watch?v=tIeHLnjs5U8\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기본 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JIYEON\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter\n",
    "하이퍼 파라미터는 모델 최적화 과정을 제어할 수 있는 조절 가능한 매개변수\n",
    "서로 다른 하이퍼 파라미터 값은 모델 학습과 convergence rate(수렴율)에 영향을 미칠 수 있다.\n",
    "\n",
    "학습 시에는 다음과 같은 하이퍼 파라미터를 정의한다.\n",
    "1. epoch : 데이터셋 반복하는 횟수\n",
    "2. batch size : 매개변수가 갱신되기 전 신경망을 통해 전파된 데이터 샘플 수\n",
    "3. learning rate : 각 배치/에폭에서 모델의 매개변수를 조절하는 비율.\n",
    "-> 값이 작을수록 학습 속도가 느리고, 값이 크면 학습 중 예측할 수 없는 동작이 발생할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최적화 단계(Optimization Loop)\n",
    "하이퍼 파라미터를 설정한 뒤에는 optimizer를 통해 모델을 학습하고 최적화 할 수 있다.\n",
    "\n",
    "최적화 단계 각 iteration을 epoch라고 부른다.\n",
    "\n",
    "\n",
    "하나의 epoch는 다음 두 부분으로 구성된다.\n",
    "1. train loop : 학습용 데이터셋을 iterate하고 최적의 매개변수로 수렴한다.\n",
    "2. val/test loop : 모델 성능이 개선되고 있는지를 확인하기 위해 테스트 데이터셋을 반복\n",
    "\n",
    "training loop에서 일어나는 몇 가지 개념들을 간략히 살펴보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss function\n",
    "학습용 데이터를 제공하면, 학습되지 않은 신경망은 정답을 제공하지 않을 확률이 높다.\n",
    "\n",
    "loss function은 획득한 결과와 실제 값 사이의 차이를 측정하며, 학습 중에 이 값을 최소화하려고 한다.\n",
    "\n",
    "주어진 데이터 샘플을 입력으로 계산한 예측과 label을 비교하여 loss를 계산\n",
    "\n",
    "\n",
    "\n",
    "일반적인 손실함수에는 regression task에 사용하는 nn.MSELoss\n",
    "\n",
    "classification에 사용하는 nn.NLLLoss(Negative Log Likelihood)\n",
    "\n",
    "nn.LogSoftmax와 nn.NLLLoss를 합친 nn.CrossEntropyLoss 등이 있다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd7d8ae84c30c9b148779bedbfd4b6b894c49078e9fff681c5971088fae95644"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('torch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
